{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: ipynb in /Users/mattiaskallman1/anaconda3/lib/python3.7/site-packages (0.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipynb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import yaml\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"..\")\n",
    "import Models\n",
    "os.chdir(\"MockPipeline\")\n",
    "\n",
    "os.chdir(\"../../pipeline\")\n",
    "import ipynb.fs.full.processing as processing\n",
    "import ipynb.fs.full.features as features\n",
    "import ipynb.fs.full.training as training\n",
    "import ipynb.fs.full.analysis as analysis\n",
    "import ipynb.fs.full.storage as storage\n",
    "import ipynb.fs.full.visualize as visualize\n",
    "os.chdir(\"../models-decision-system/MockPipeline\")\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras import Input, Model\n",
    "\n",
    "from tcn import TCN, tcn_full_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml(path):\n",
    "    with open(path, mode='r') as file:\n",
    "        return yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = load_yaml('mock_settings.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings['ensemble']['models'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = processing.create_dataframe(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = features.add(dataframe, settings['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_linreg = features.split(dataset, 'linreg', settings['ensemble']['models'][0]['linreg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lstm = features.split(dataset, 'lstm', settings['ensemble']['models'][1]['lstm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings['ensemble']['models'][1]['lstm']['layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING\n",
    "#linreg = Models.train_model(data_linreg, 'linreg', settings['ensemble']['models'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WORKING\n",
    "#lstm = Models.train_model(data_lstm, 'lstm', settings['ensemble']['models'][1]['lstm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WORKING\n",
    "#tcn = Models.train_model(data_lstm, 'tcn', settings['ensemble']['models'][3]['tcn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Time Based Cross Validation](https://towardsdatascience.com/time-based-cross-validation-d259b13d42b8)\n",
    "https://github.com/orhermansaffar/TimeBasedCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "from dateutil.relativedelta import *\n",
    "\n",
    "class TimeBasedCV(object):\n",
    "    '''\n",
    "    Parameters \n",
    "    ----------\n",
    "    train_period: int\n",
    "        number of time units to include in each train set\n",
    "        default is 30\n",
    "    test_period: int\n",
    "        number of time units to include in each test set\n",
    "        default is 7\n",
    "    freq: string\n",
    "        frequency of input parameters. possible values are: days, months, years, weeks, hours, minutes, seconds\n",
    "        possible values designed to be used by dateutil.relativedelta class\n",
    "        deafault is days\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, train_period=30, test_period=7, freq='days'):\n",
    "        self.train_period = train_period\n",
    "        self.test_period = test_period\n",
    "        self.freq = freq\n",
    "\n",
    "        \n",
    "        \n",
    "    def split(self, data, validation_split_date=None, date_column='record_date', gap=0):\n",
    "        '''\n",
    "        Generate indices to split data into training and test set\n",
    "        \n",
    "        Parameters \n",
    "        ----------\n",
    "        data: pandas DataFrame\n",
    "            your data, contain one column for the record date \n",
    "        validation_split_date: datetime.date()\n",
    "            first date to perform the splitting on.\n",
    "            if not provided will set to be the minimum date in the data after the first training set\n",
    "        date_column: string, deafult='record_date'\n",
    "            date of each record\n",
    "        gap: int, default=0\n",
    "            for cases the test set does not come right after the train set,\n",
    "            *gap* days are left between train and test sets\n",
    "        \n",
    "        Returns \n",
    "        -------\n",
    "        train_index ,test_index: \n",
    "            list of tuples (train index, test index) similar to sklearn model selection\n",
    "        '''\n",
    "        \n",
    "        # check that date_column exist in the data:\n",
    "        try:\n",
    "            data[date_column]\n",
    "        except:\n",
    "            raise KeyError(date_column)\n",
    "                    \n",
    "        train_indices_list = []\n",
    "        test_indices_list = []\n",
    "\n",
    "        if validation_split_date==None:\n",
    "            validation_split_date = data[date_column].min().date() + eval('relativedelta('+self.freq+'=self.train_period)')\n",
    "        \n",
    "        start_train = validation_split_date - eval('relativedelta('+self.freq+'=self.train_period)')\n",
    "        end_train = start_train + eval('relativedelta('+self.freq+'=self.train_period)')\n",
    "        start_test = end_train + eval('relativedelta('+self.freq+'=gap)')\n",
    "        end_test = start_test + eval('relativedelta('+self.freq+'=self.test_period)')\n",
    "\n",
    "        while end_test < data[date_column].max().date():\n",
    "            # train indices:\n",
    "            cur_train_indices = list(data[(data[date_column].dt.date>=start_train) & \n",
    "                                     (data[date_column].dt.date<end_train)].index)\n",
    "\n",
    "            # test indices:\n",
    "            cur_test_indices = list(data[(data[date_column].dt.date>=start_test) &\n",
    "                                    (data[date_column].dt.date<end_test)].index)\n",
    "            \n",
    "            #print(\"Train period:\",start_train,\"-\" , end_train, \", Test period\", start_test, \"-\", end_test,\n",
    "            #      \"# train records\", len(cur_train_indices), \", # test records\", len(cur_test_indices))\n",
    "\n",
    "            train_indices_list.append(cur_train_indices)\n",
    "            test_indices_list.append(cur_test_indices)\n",
    "\n",
    "            # update dates:\n",
    "            start_train = start_train + eval('relativedelta('+self.freq+'=self.test_period)')\n",
    "            end_train = start_train + eval('relativedelta('+self.freq+'=self.train_period)')\n",
    "            start_test = end_train + eval('relativedelta('+self.freq+'=gap)')\n",
    "            end_test = start_test + eval('relativedelta('+self.freq+'=self.test_period)')\n",
    "\n",
    "        # mimic sklearn output  \n",
    "        index_output = [(train,test) for train,test in zip(train_indices_list,test_indices_list)]\n",
    "\n",
    "        self.n_splits = len(index_output)\n",
    "        \n",
    "        return index_output\n",
    "    \n",
    "    \n",
    "    def get_n_splits(self):\n",
    "        \"\"\"Returns the number of splitting iterations in the cross-validator\n",
    "        Returns\n",
    "        -------\n",
    "        n_splits : int\n",
    "            Returns the number of splitting iterations in the cross-validator.\n",
    "        \"\"\"\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>SD</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>0.788775</td>\n",
       "      <td>0.346918</td>\n",
       "      <td>0.120742</td>\n",
       "      <td>0.801102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>0.801102</td>\n",
       "      <td>0.382619</td>\n",
       "      <td>0.111121</td>\n",
       "      <td>0.783473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010-02-03</td>\n",
       "      <td>0.783473</td>\n",
       "      <td>0.326071</td>\n",
       "      <td>0.081578</td>\n",
       "      <td>0.747343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010-02-04</td>\n",
       "      <td>0.747343</td>\n",
       "      <td>0.310077</td>\n",
       "      <td>0.078393</td>\n",
       "      <td>0.732836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>0.732836</td>\n",
       "      <td>0.361426</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.724710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>0.140181</td>\n",
       "      <td>0.592028</td>\n",
       "      <td>0.556347</td>\n",
       "      <td>0.141742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>0.141742</td>\n",
       "      <td>0.581530</td>\n",
       "      <td>0.512003</td>\n",
       "      <td>0.157833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>0.157833</td>\n",
       "      <td>0.596336</td>\n",
       "      <td>0.501223</td>\n",
       "      <td>0.160129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>0.160129</td>\n",
       "      <td>0.576133</td>\n",
       "      <td>0.502554</td>\n",
       "      <td>0.164719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>0.164719</td>\n",
       "      <td>0.618668</td>\n",
       "      <td>0.522338</td>\n",
       "      <td>0.170779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3101 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Close  Momentum        SD     Label\n",
       "Date_Timestamp                                        \n",
       "2010-02-01      0.788775  0.346918  0.120742  0.801102\n",
       "2010-02-02      0.801102  0.382619  0.111121  0.783473\n",
       "2010-02-03      0.783473  0.326071  0.081578  0.747343\n",
       "2010-02-04      0.747343  0.310077  0.078393  0.732836\n",
       "2010-02-05      0.732836  0.361426  0.085275  0.724710\n",
       "...                  ...       ...       ...       ...\n",
       "2019-12-25      0.140181  0.592028  0.556347  0.141742\n",
       "2019-12-26      0.141742  0.581530  0.512003  0.157833\n",
       "2019-12-27      0.157833  0.596336  0.501223  0.160129\n",
       "2019-12-29      0.160129  0.576133  0.502554  0.164719\n",
       "2019-12-30      0.164719  0.618668  0.522338  0.170779\n",
       "\n",
       "[3101 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to use TimeBasedCV\n",
    "data_for_modeling=dataset.reset_index()\n",
    "tscv = TimeBasedCV(train_period=30,\n",
    "                   test_period=7,\n",
    "                   freq='days')\n",
    "for train_index, test_index in tscv.split(data_for_modeling, date_column='Date_Timestamp'):\n",
    "    continue\n",
    "\n",
    "# get number of splits\n",
    "tscv.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fc69a90cfeca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### Example- compute average test sets score: ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_for_modeling\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_for_modeling\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'columns' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#### Example- compute average test sets score: ####\n",
    "X = data_for_modeling[['Close',columns]]\n",
    "y = data_for_modeling[label]\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in tscv.split(X, validation_split_date=datetime.date(2019,2,1)):\n",
    "\n",
    "    data_train   = X.loc[train_index].drop('record_date', axis=1)\n",
    "    target_train = y.loc[train_index]\n",
    "\n",
    "    data_test    = X.loc[test_index].drop('record_date', axis=1)\n",
    "    target_test  = y.loc[test_index]\n",
    "\n",
    "    # if needed, do preprocessing here\n",
    "\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(data_train,target_train)\n",
    "\n",
    "    preds = clf.predict(data_test)\n",
    "\n",
    "    # accuracy for the current fold only    \n",
    "    r2score = clf.score(data_test,target_test)\n",
    "\n",
    "    scores.append(r2score)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "average_r2score = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LightGBM](https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
