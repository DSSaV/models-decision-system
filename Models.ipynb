{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "#  TODO:REMOVE IF NOT NEEDED\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.python.keras import Sequential, Input, Model\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "from tcn import TCN, tcn_full_summary\n",
    "\n",
    "\n",
    "def linear_regression(data, settings):\n",
    "    \"\"\"Creates a linear regression model and predictions.\n",
    "\n",
    "    Args:\n",
    "        data: pandas.DataFrame.\n",
    "        settings: Dictionary object containing settings parameters.\n",
    "    Returns:\n",
    "        A dictionary containing the linear regression model and predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    #  VARIABLES\n",
    "    x_train = data['train']['features']\n",
    "    y_train = data['train']['labels']\n",
    "    x_test = data['test']['features']\n",
    "\n",
    "    #  INSTANTIATE MODEL\n",
    "    linear = LinearRegression()\n",
    "\n",
    "    #  CREATE PREDICTIONS USING TEST DATA\n",
    "    model = linear.fit(x_train, y_train)\n",
    "\n",
    "    #  PREDICTIONS\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "\n",
    "def create_generator(dataset, params, shuffle=True):\n",
    "    # DECONSTRUCT DATASET\n",
    "    features = dataset['features']\n",
    "    labels = dataset['labels']\n",
    "\n",
    "    # DECONSTRUCT PARAMS\n",
    "    batch = params['batch']\n",
    "    window = params['window']\n",
    "\n",
    "    # GENERATE & RETURN\n",
    "    return TimeseriesGenerator(\n",
    "        features,\n",
    "        labels,\n",
    "        length=window,\n",
    "        batch_size=batch,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "\n",
    "\n",
    "def add_lstm_layer(model, data, index, name, settings, shape):\n",
    "    \"\"\"Support function used to add a Keras Layers to the LSTM model.\"\"\"\n",
    "\n",
    "    # AVAILABLE LAYERS\n",
    "    available = {\n",
    "        'lstm': LSTM,\n",
    "        'dropout': Dropout,\n",
    "        'dense': Dense\n",
    "    }\n",
    "\n",
    "    # SELECT THE CORRECT FUNCTION\n",
    "    func = available[name]\n",
    "\n",
    "    # IF AN ACTIVATION IS FOUND & THIS IS THE FIRST LAYER\n",
    "    model.add(func(**settings))\n",
    "\n",
    "\n",
    "def add_lstm_layers(model, data, settings, shape):\n",
    "    \"\"\"Support function that loops through all available Keras Layers.\"\"\"\n",
    "\n",
    "    # LOOP THROUGH REQUESTED MODEL LAYERS\n",
    "    for index, layer in enumerate(settings['layers']):\n",
    "        # LAYER PROPS\n",
    "        name = list(layer)[0]\n",
    "        params = layer[name]\n",
    "\n",
    "        # GENERATE & ADD THE LAYER\n",
    "        add_lstm_layer(model, data, index, name, params, shape)\n",
    "\n",
    "\n",
    "def long_short_term_memory(data, settings):\n",
    "    \"\"\"Creates a Long short-term memory model (LSTM) and predictions.\n",
    "\n",
    "    Args:\n",
    "        data: pandas.DataFrame.\n",
    "        settings: Dictionary object containing settings parameters.\n",
    "    Returns:\n",
    "        A dictionary containing the LSTM model and predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    #  INSTANTIATE MODEL\n",
    "    model = Sequential()\n",
    "\n",
    "    #  TRAIN DATA GENERATOR\n",
    "    train_generator = create_generator(\n",
    "        data['train'],\n",
    "        settings['morph'],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    #  ADDING LAYERS TO MODEL\n",
    "    add_lstm_layers(model, data, settings, train_generator[0][0].shape)\n",
    "\n",
    "    #  COMPILE THE MODEL\n",
    "    model.compile(\n",
    "        loss=settings['loss'],\n",
    "        optimizer=settings['optimizer']\n",
    "    )\n",
    "\n",
    "    #  TRAIN USING TRAIN DATA\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=settings['epochs'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    #  TEST DATA GENERATOR\n",
    "    test_generator = create_generator(\n",
    "        data['test'],\n",
    "        settings['morph'],\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    #  PREDICT USING TEST DATA\n",
    "    predictions = model.predict(test_generator)\n",
    "\n",
    "    # denormalized_predictions = \"\"\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "\n",
    "def add_tcn_layer(name, model_output, settings, index):\n",
    "    \"\"\"Support function that adds Keras Layers to TCN model.\"\"\"\n",
    "\n",
    "    # AVAILABLE LAYERS\n",
    "    available = {\n",
    "        'dropout': Dropout,\n",
    "        'dense': Dense\n",
    "    }\n",
    "\n",
    "    # SELECT THE CORRECT FUNCTION\n",
    "    func = available[name]\n",
    "    return func(**settings)(model_output)\n",
    "\n",
    "\n",
    "def add_tcn_layers(model_input, settings):\n",
    "    \"\"\"Support function that adds TCN Layer and requested Keras Layers to the TCN model\"\"\"\n",
    "\n",
    "    layers = settings['layers']\n",
    "\n",
    "    try:\n",
    "        model_output = TCN(**settings['layers'][0]['tcn'])(model_input)\n",
    "    except ValueError as e:\n",
    "        print(e, 'Wrong structure on yaml config file')\n",
    "\n",
    "    for index, layer in enumerate(layers):\n",
    "        name = list(layer)[0]\n",
    "        params = layer[name]\n",
    "        if name == 'tcn':\n",
    "            continue\n",
    "        else:\n",
    "            model_output = add_tcn_layer(name, model_output, params, index)\n",
    "\n",
    "    return model_output\n",
    "\n",
    "\n",
    "def temporal_convolutional_network(data, settings):\n",
    "    \"\"\"Creates a Temporal Convolutional Network model (TCN) and predictions.\n",
    "\n",
    "        Args:\n",
    "            data: pandas.DataFrame.\n",
    "            settings: Dictionary object containing settings parameters.\n",
    "        Returns:\n",
    "            A dictionary containing the TCN model and predictions.\n",
    "        \"\"\"\n",
    "\n",
    "    #  TRAIN DATA GENERATOR\n",
    "    train_generator = create_generator(\n",
    "        data['train'],\n",
    "        settings['morph'],\n",
    "        shuffle=True\n",
    "    )\n",
    "    #  TRAIN DATA GENERATOR\n",
    "    test_generator = create_generator(\n",
    "        data['test'],\n",
    "        settings['morph'],\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    #  INSTANTIATE KERAS TENSOR INPUT WITH TIMESERIESGENEREATOR SHAPE\n",
    "    model_input = Input(batch_shape=train_generator[0][0].shape)\n",
    "\n",
    "    #  INSTANTIATE MODEL LAYERS\n",
    "    model_output = add_tcn_layers(model_input, settings)\n",
    "\n",
    "    #  INSTANTIATE MODEL AND ASSIGN INPUT AND OUTPUT\n",
    "    model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "    # COMPILE THE MODEL\n",
    "    model.compile(optimizer=settings['optimizer'], loss=settings['loss'])\n",
    "\n",
    "    #  PRINT MODEL STATS\n",
    "    tcn_full_summary(model, expand_residual_blocks=False)\n",
    "\n",
    "    #  TRAIN THE MODEL WITH VALIDATION\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=settings['epochs'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    #  PREDICT USING TEST DATA\n",
    "    predictions = model.predict(test_generator)\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "\n",
    "def linear_support_vector_classifier(data, settings):\n",
    "    \"\"\"Creates a Linear Support Vector Classifier (Linear SVC) and predictions.\n",
    "\n",
    "    Args:\n",
    "        data: pandas.DataFrame.\n",
    "        settings: Dictionary object containing settings parameters, Labels have to be buy/sell/hold or another classification type\n",
    "    Returns:\n",
    "        A dictionary containing the Linear SVC model and predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    #  VARIABLES\n",
    "    x_train = data['train']['features']\n",
    "    y_train = data['train']['labels']\n",
    "    x_test = data['test']['features']\n",
    "    scaler = data['scaler']\n",
    "\n",
    "    # INSTANTIATE MODEL\n",
    "    model = LinearSVC()\n",
    "\n",
    "    # CREATE PREDICTIONS USING TRAIN DATA\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # PREDICTIONS\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "def grid_search_model(model, data, settings):\n",
    "    \"\"\"Runs a grid search on the given model to define the best parameters for the model. \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: sklearn model \n",
    "    unfitted model\n",
    "    dataset: dict\n",
    "    Dictionary that contains x_train, y_train, features and labels\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model: sklearn model\n",
    "    Same type of model as the input model, with optimized parameters\n",
    "    \n",
    "    \n",
    "    Example dicts:\n",
    "    --------------\n",
    "    \n",
    "    Random Forest:\n",
    "    --------------\n",
    "    grid_settings = {\n",
    "        \"cv\": 3, # number of folds\n",
    "        \"n_jobs\": -1, # processors to use during grid search\n",
    "        'grid_params': { # parameters for grid search (specific to each model)\n",
    "            'n_estimators': [10,50,100,300], # int\n",
    "            'max_features': ['log2', 'sqrt'], # {“sqrt”, “log2”}, int or float\n",
    "            'max_depth': [10,100, None], # int, default=None\n",
    "            'min_samples_split': [3, 10], # int or float, default=2\n",
    "            'min_samples_leaf': [2, 4], # int or float, default=1\n",
    "            'bootstrap': [True, False], # bool, default=True\n",
    "            \"class_weight\": [\"balanced\"] # {“balanced”, “balanced_subsample”}, dict or list of dicts, default=None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Logistical Regression:\n",
    "    ----------------------\n",
    "    grid_settings = {\n",
    "        \"cv\": 3, # number of folds\n",
    "        \"n_jobs\": -1, # processors to use during grid search\n",
    "        'grid_params': {\n",
    "            \"C\": [0.001, 0.1, 1,10,100,1000],\n",
    "            \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n",
    "            \"solver\": [\"lbfgs\", \"sag\", \"newton-cg\"],\n",
    "            \"multi_class\": [\"ovr\", \"auto\", \"multinomial\"],\n",
    "            \"max_iter\": [100,1000, 10000],\n",
    "            \"class_weight\": [\"balanced\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Gaussian Naive Bayes:\n",
    "    ---------------------\n",
    "    grid_settings = {\n",
    "        \"cv\": 3, # number of folds\n",
    "        \"n_jobs\": -1, # processors to use during grid search\n",
    "        \"grid_params\":{\n",
    "            \"var_smoothing\": [1e-9, 1e-10, 1e-5]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Complementary Naive Bayes:\n",
    "    --------------------------\n",
    "    grid_settings = {\n",
    "        \"cv\": 3, # number of folds\n",
    "        \"n_jobs\": -1, # processors to use during grid search\n",
    "        \"grid_params\":{\n",
    "\n",
    "            \"alpha\": [0.5, 1],\n",
    "            \"norm\": [True, False],\n",
    "\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #  VARIABLES\n",
    "    x_train = data['train']['features']\n",
    "    y_train = data['train']['labels']\n",
    "    x_test = data['test']['features']\n",
    "    y_test = data['test']['labels']\n",
    "    x = np.concatenate((x_train, x_test))\n",
    "    y = np.concatenate((y_train, y_test))\n",
    "    \n",
    "    # CREATE GRID SEARCH CV\n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = settings[\"grid_params\"], \n",
    "                          cv = settings[\"cv\"], n_jobs = settings[\"n_jobs\"], verbose = 2)\n",
    "    \n",
    "    # FIT GRIDSEARCH\n",
    "    grid_search.fit(x, y)\n",
    "    \n",
    "    # PICK OUT THE BEST MODEL FROM GRID SEARCH\n",
    "    model = grid_search.best_estimator_\n",
    "    \n",
    "    # RUN MODEL ON BEST PARAMS   \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # RETURN MODEL WITH BEST PARAMS    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(dataset, name, settings):\n",
    "    # AVAILABLE MODELS\n",
    "    model = {\n",
    "        'linreg': linear_regression,\n",
    "        'lstm': long_short_term_memory,\n",
    "        'tcn': temporal_convolutional_network,\n",
    "        'svc': linear_support_vector_classifier\n",
    "    }\n",
    "\n",
    "    # SELECT THE CORRECT FUNCTION & START\n",
    "    return model[name](dataset, settings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
